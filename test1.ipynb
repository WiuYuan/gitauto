{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.services.llm import LLM\n",
    "from src.services.logical_tree import LogicalTree\n",
    "from src.utils.build_agent import build_agent, query_based_on_tool_calls, fix_github_error\n",
    "from typing import Callable, List, Dict, Any\n",
    "from src.services.agents import Tool_Calls\n",
    "\n",
    "# from src.services.agents import Agent, Tool\n",
    "from src.services.custom_tools import custom_tools, clean_training_logs\n",
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ[\"NO_PROXY\"] = \"*\"\n",
    "\n",
    "# llm = LLM(model_name=\"qwen3:8b\")\n",
    "\n",
    "llm = LLM(\n",
    "    model_name=\"deepseek-chat\",\n",
    "    llm_url=\"https://api.deepseek.com/chat/completions\",\n",
    "    api_key=\"sk-2332c3d16a8d4f4ba1b3503074ba04c5\",\n",
    "    format=\"openai\",\n",
    ")\n",
    "# llm = LLM(\n",
    "#     model_name=\"gpt-5-2025-08-07\",\n",
    "#     llm_url=\"https://api.aimlapi.com/v1/chat/completions\",\n",
    "#     api_key=\"9ce046a9681446c48427b3fe4dd7cdd4\",\n",
    "#     format=\"openai\",\n",
    "# )\n",
    "# llm = LLM(\n",
    "#     model_name=\"gpt-4o-mini\",\n",
    "#     llm_url=\"https://api.aimlapi.com/v1/chat/completions\",\n",
    "#     api_key=\"9ce046a9681446c48427b3fe4dd7cdd4\",\n",
    "#     format=\"openai\",\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "ct = custom_tools(\n",
    "    HOST_DIR=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/agent/issue_fix\",\n",
    "    HOST_DATA_DIR=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/data/issue_fix\",\n",
    "    MAIN_DIR=\"/workspace\",\n",
    "    MAIN_DATA_DIR=\"/data\",\n",
    "    PYTHON_PATH=\"python\",\n",
    "    MATLAB_PATH=\"/Applications/MATLAB_R2023b.app/bin/matlab\",\n",
    "    ENV_NAME=\"agent1\",\n",
    "    LOCAL_TMP_PATH=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/tmp\",\n",
    "    REMOTE_TMP_PATH=\"/tmp\",\n",
    "    BASE_ENV=\"python:3.7\",\n",
    "    PMC_URL=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC7567795\",\n",
    "    llm=llm,\n",
    ")\n",
    "from src.services.llm import load_messages, save_messages\n",
    "tool_calls_path = \"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/code/tool_calls_path.json\"\n",
    "env_tool_calls_path = \"/workspace/tool_calls_path.json\"\n",
    "# previous_tool_calls = load_messages(tool_calls_path)\n",
    "# def update_content_with_clearlog(previous_tool_call, tool_name, tool_id, clearlog_func):\n",
    "#     for item in previous_tool_call:\n",
    "#         if item.get(\"name\") == tool_name and item.get(\"tool_call_id\") == tool_id:\n",
    "#             original_content = item.get(\"content\", \"\")\n",
    "#             cleaned_content = clearlog_func(original_content)\n",
    "#             item[\"content\"] = cleaned_content\n",
    "#             return cleaned_content\n",
    "#     return None\n",
    "\n",
    "# 用法\n",
    "# cleaned = update_content_with_clearlog(\n",
    "#     previous_tool_calls,\n",
    "#     \"func_cmd\",\n",
    "#     \"call_00_N7b0LUYT8t6svwV9wM7cF2VC\",\n",
    "#     clean_training_logs  # 你之前写好的 clearlog 函数\n",
    "# )\n",
    "\n",
    "# print(cleaned)\n",
    "# # # previous_toll_calls = []\n",
    "# # # previous_toll_calls.extend(generate_tool_calls(ct.MAIN_DIR))\n",
    "# save_messages(previous_tool_calls, tool_calls_path)\n",
    "\n",
    "\n",
    "# def func1(a: int) -> int:\n",
    "#     return a + 1\n",
    "# tools = [func1]\n",
    "# tc = Tool_Calls(PATH=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/test.json\")\n",
    "# llm.query_with_tools(prompt=\"What is func1(1)+func1(2)?\", tc=tc, max_steps=1, tools=tools, verbose=True)\n",
    "# llm.query(\"Please tell me who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Cloning GitHub repository...\n",
      "\n",
      "\n",
      "[INFO] Starting LLM query for goal 1...\n",
      "\n",
      "[INFO] Recomputed 0 nodes in total (excluding layer 0).\n",
      "\n",
      "[LLM] Query with Tools\n",
      "  [INPUT]\n",
      "    You are solving a task step by step using a logical tree.\n",
      "    \n",
      "    - The **current node** you are working on is:\n",
      "      - Name: test github code\n",
      "      - Description: MAIN_DIR/package/ is a GitHub package I downloaded.\n",
      "    Please run tests with both **real** and **sample** data and output the prediction results.\n",
      "    You **must compare the prediction results calculated by yourself with the results in the corresponding PMC article by calling func_fetch_info_from_pmc_with_llm**.\n",
      "    The result should be equal to the paper, but perhaps due to some reason, it may not be correct.\n",
      "    Any test code you write using tools should be placed under MAIN_DIR/,\n",
      "    MAIN_DIR=/workspace. You must provide all necessary parameters to the tools.\n",
      "    When installing dependencies, the main goal is to minimize local resource consumption \n",
      "    (e.g., by using precompiled wheels whenever possible).\n",
      "    Please note that when data missed you can use func_think tool.\n",
      "    If any instructions exist in tool calls, follow them instead of the guidelines here.\n",
      "    \n",
      "    ### Instructions\n",
      "    1. Think of methods to achieve the goal starting from the **current node**.\n",
      "    2. You may break the task into **subtasks**. Each subtask must be added as a child node in the tree by calling the function:\n",
      "       - add_child(name: str, description: str) → creates a new task under the current node and moves focus into it.\n",
      "    3. Within each subtask, you may attempt different approaches using the available tools.\n",
      "       - If an approach succeeds or fails, finalize that subtask by calling:\n",
      "         - return_to_parent(result: str, success: bool) → stores the result and moves back to the parent node.\n",
      "    4. Always maintain a clear logical tree structure:\n",
      "       - One root goal.\n",
      "       - Each node representing a subtask with a clear name, description, and result.\n",
      "       - When a path fails, return to the parent and try an alternative subtask.\n",
      "       - When a path succeeds, return to the parent and mark it successful.\n",
      "    \n",
      "    ### Your objective\n",
      "    Keep reasoning forward until the **overall goal** is accomplished, while keeping the logical tree clear, consistent, and hierarchical.\n",
      "\n",
      "  [OUTPUT]\n",
      "    Failed to parse JSON from line: \n",
      "[{'role': 'user', 'content': 'You are solving a task step by step using a logical tree.\\n\\n- The **current node** you are working on is:\\n  - Name: test github code\\n  - Description: MAIN_DIR/package/ is a GitHub package I downloaded.\\nPlease run tests with both **real** and **sample** data and output the prediction results.\\nYou **must compare the prediction results calculated by yourself with the results in the corresponding PMC article by calling func_fetch_info_from_pmc_with_llm**.\\nThe result should be equal to the paper, but perhaps due to some reason, it may not be correct.\\nAny test code you write using tools should be placed under MAIN_DIR/,\\nMAIN_DIR=/workspace. You must provide all necessary parameters to the tools.\\nWhen installing dependencies, the main goal is to minimize local resource consumption \\n(e.g., by using precompiled wheels whenever possible).\\nPlease note that when data missed you can use func_think tool.\\nIf any instructions exist in tool calls, follow them instead of the guidelines here.\\n\\n### Instructions\\n1. Think of methods to achieve the goal starting from the **current node**.\\n2. You may break the task into **subtasks**. Each subtask must be added as a child node in the tree by calling the function:\\n   - add_child(name: str, description: str) → creates a new task under the current node and moves focus into it.\\n3. Within each subtask, you may attempt different approaches using the available tools.\\n   - If an approach succeeds or fails, finalize that subtask by calling:\\n     - return_to_parent(result: str, success: bool) → stores the result and moves back to the parent node.\\n4. Always maintain a clear logical tree structure:\\n   - One root goal.\\n   - Each node representing a subtask with a clear name, description, and result.\\n   - When a path fails, return to the parent and try an alternative subtask.\\n   - When a path succeeds, return to the parent and mark it successful.\\n\\n### Your objective\\nKeep reasoning forward until the **overall goal** is accomplished, while keeping the logical tree clear, consistent, and hierarchical.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_00_uYjM2msZSWOY2MFuhPuuHA', 'type': 'function', 'function': {'name': 'func_cmd', 'arguments': '{\"command\": \"cd /workspace && git clone https://github.com/lungproject/lungegfr package\"}'}, 'index': 0, 'name': 'func_cmd'}]}, {'role': 'tool', 'name': 'func_cmd', 'tool_call_id': 'call_00_uYjM2msZSWOY2MFuhPuuHA', 'content': \"(code 128, status=Run the Command Failed):\\nTotal chunks: 1\\nSTDOUT (selected chunks):\\n--- Chunk 1 ---\\n[No output generated]\\nSTDERR:\\nfatal: destination path 'package' already exists and is not an empty directory.\\n\"}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_00_MEdH4ol8R1Sg0pGfggbViA', 'type': 'function', 'function': {'name': 'add_child', 'arguments': '{\"goal_name\": \"test github code\", \"goal_description\": \"MAIN_DIR/package/ is a GitHub package I downloaded.\\\\nPlease run tests with both **real** and **sample** data and output the prediction results.\\\\nYou **must compare the prediction results calculated by yourself with the results in the corresponding PMC article by calling func_fetch_info_from_pmc_with_llm**.\\\\nThe result should be equal to the paper, but perhaps due to some reason, it may not be correct.\\\\nAny test code you write using tools should be placed under MAIN_DIR/,\\\\nMAIN_DIR=/workspace. You must provide all necessary parameters to the tools.\\\\nWhen installing dependencies, the main goal is to minimize local resource consumption \\\\n(e.g., by using precompiled wheels whenever possible).\\\\nPlease note that when data missed you can use func_think tool.\\\\nIf any instructions exist in tool calls, follow them instead of the guidelines here.\"}'}, 'index': 0, 'name': 'add_child'}]}, {'role': 'tool', 'name': 'add_child', 'tool_call_id': 'call_00_MEdH4ol8R1Sg0pGfggbViA', 'content': 'Successfully add node with name [test github code]'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_00_f6KQ8_uPQJeE47rRbIqujA', 'type': 'function', 'function': {'name': 'func_guide', 'arguments': '{\"guidance\": \"Will Return Guidance\"}'}, 'index': 0, 'name': 'func_guide'}]}, {'role': 'tool', 'name': 'func_guide', 'tool_call_id': 'call_00_f6KQ8_uPQJeE47rRbIqujA', 'content': 'You have access to the following tools. \\nEach tool has a name and a description of what it does. \\nWhen you decide a tool is needed, please call it explicitly.\\n\\nHere are the available tools:\\n\\n- func_cat: Safely display contents of a file under MAIN_DIR, only if UTF-8,\\n        and optionally return selected chunks of the output.\\n\\n        Parameters:\\n            filepath (str): Relative path under MAIN_DIR, e.g., \\'agent1/main.sh\\'.\\n            return_chunk_indices (list[int]): 1-based indices of chunks to return. Negative indices allowed. Default [1, -1].\\n\\n        Returns:\\n            str: Selected stdout chunks with metadata and simplified error message if failed.\\n- func_cat_with_llm: Let another LLM view and analyze the content of a specified file in chunks.\\n\\n        Procedure:\\n            1. Read the full file content using _func_cat.\\n            2. Split the content into chunks based on max_chars with overlap.\\n            3. For each chunk, call the LLM to analyze the chunk with the provided request.\\n            4. Combine the results and return as a single string.\\n\\n        Args:\\n            filepath (str): The path to the file to read.\\n            request (str): A question or instruction regarding the file content.\\n            max_chars (int): Maximum characters per chunk.\\n            overlap (int): Number of overlapping characters between chunks.\\n\\n        Returns:\\n            str: Combined LLM analysis of all chunks.\\n- func_write: Write the given text to a file inside the project directory.\\n\\n        Parameters:\\n            filepath (str): Relative path under MAIN_DIR, e.g., \\'agent1/main.sh\\'.\\n            text (str): Text content to write to the file.\\n\\n        Returns:\\n            str: Confirmation message indicating the file has been written.\\n\\n        Example:\\n            input: \\'agent1/main.sh\\', \\'echo hello\\'\\n            output: \\'Written to agent1/main.sh\\'\\n- func_modify: Safely attempt to modify existing text in a file by replacing old_text with new_text. If the pattern is not found, an error message will be returned. After modifying, it\\'s advisable to double-check the file for proper format.\\n            filepath (str): Relative path under MAIN_DIR, e.g., \\'agent1/main.sh\\'.\\n            old_text (str): The text pattern to be replaced.\\n            new_text (str): The new text to replace the old text.\\n\\n        Returns:\\n            str: Confirmation message indicating the modification has been done.\\n\\n        Example:\\n            input: \\'agent1/main.sh\\', \\'echo hello\\', \\'echo world\\'\\n            output: \\'Modified agent1/main.sh: replaced \"echo hello\" with \"echo world\"\\'\\n- func_insert: Safely attempt to insert new text after a specific pattern in a file. If the pattern is not found, an error message will be returned. After inserting, it\\'s advisable to double-check the file for proper format. If the pattern is not found, an error message will be returned. After modifying, it\\'s advisable to double-check the file for proper format.\\n            filepath (str): Relative path under MAIN_DIR.\\n            insert_after (str): The text pattern after which to insert new content.\\n            new_text (str): The text to insert.\\n\\n        Returns:\\n            str: Confirmation message.\\n\\n        Example:\\n            input: \\'agent1/main.sh\\', \\'import os\\', \\'import sys\\'\\n            output: \\'Inserted text after \"import os\" in agent1/main.sh\\'\\n- func_append: Append text to the end of a file. If the pattern is not found, an error message will be returned. After modifying, it\\'s advisable to double-check the file for proper format.\\n            filepath (str): Relative path under MAIN_DIR.\\n            new_text (str): The text to append.\\n\\n        Returns:\\n            str: Confirmation message.\\n- func_prepend: Prepend text to the beginning of a file. If the pattern is not found, an error message will be returned. After modifying, it\\'s advisable to double-check the file for proper format.\\n            filepath (str): Relative path under MAIN_DIR.\\n            new_text (str): The text to prepend.\\n\\n        Returns:\\n            str: Confirmation message.\\n- func_python: Run a Python script located at \\'filepath\\' inside the given working directory\\n        (relative to MAIN_DIR).\\n\\n        The function will first \\'cd ${MAIN_DIR}/{workdir}\\' and then run the script\\n        using the designated Python environment.\\n\\n        Any error messages generated by the script will be captured and automatically\\n        simplified using the LLM before being returned.\\n\\n        Example:\\n        func_python(filepath=\"test/test.py\", workdir=\"agent1\")\\n        will run:\\n        \\'cd ${MAIN_DIR}/agent1 && python ${MAIN_DIR}/agent1/test/test.py\\'\\n- func_cmd: This function writes the command to a .sh file and then executes it using bash, capture stdout/stderr, and optionally return selected chunks of stdout.\\n\\n        Args:\\n            command (str): The command to run.\\n            return_chunk_indices (list[int]): 1-based indices of chunks to return.\\n                Negative indices are allowed (like Python lists). Default is [1, -1] (first and last chunk).\\n\\n        Returns:\\n            str: Selected stdout chunks with metadata and simplified error message if failed.\\n- func_matlab: Run a MATLAB script at the specified path.\\n\\n        Note:\\n        - You must use this function to run MATLAB scripts instead of func_cmd.\\n        - This function is configured with a dedicated MATLAB module, so it will always run successfully\\n        even if MATLAB is not in the system PATH.\\n\\n        Example:\\n            input \\'test/test.m\\' will run the script.\\n            MATLAB will first change directory to the script\\'s folder,\\n            then execute the script.\\n- func_fetch_info_from_pmc_with_llm: Fetch information from a PMC article using LLM.\\n\\n        Args:\\n            request (str): A question or instruction regarding the content of the article.\\n\\n        Returns:\\n            str: Analysis or answer from the LLM based on the article content.\\n- func_human: Use this tool when the model cannot resolve an issue automatically.\\n\\n        This agent is specifically designed to request **human assistance** for errors,\\n        unresolved problems, or ambiguous situations. When invoked, it will prompt a human\\n        to provide a solution or guidance and will return the human-provided response.\\n\\n        The model should call this tool **only when all automated methods have failed**\\n        and a human response is necessary to continue.\\n- func_guide: Never use this tool by yourself.\\n\\n        This agent is specifically designed to derive someone else guidance.\\n\\n        it will return guidance by others to you.\\n- add_child: This function adds a new child node to the current node, but it **must not be called directly**.\\n\\n        If you want to add a new child node, please use the higher-level helper function\\n        `help_add_child(info)` instead. `help_add_child` will handle the logic and call this\\n        method internally.\\n\\n        Args:\\n            name (str): The name of the child node to be created.\\n            description (str, optional): A short description of the child node.\\n                Defaults to an empty string.\\n\\n        Returns:\\n            str: A message indicating that this function should not be called directly.\\n- return_to_parent: This function finalize the current node with a result and move back to its parent node., but it **must not be called directly**.\\n\\n        If you want to finalize the current node, please use the higher-level helper function\\n        `help_return_to_parent(info)` instead. `help_return_to_parent` will handle the logic and call this\\n        method internally.\\n\\n        Args:\\n            result (Any, optional): The result or message describing the outcome\\n                of the current node. Can include success output or failure details.\\n            success (bool, optional): Whether the current node is considered\\n                successful (True) or failed (False). Defaults to True.\\n\\n        Returns:\\n            LogicalTree.Node: The parent node of the finalized current node.\\n                If the current node has no parent, it will remain as the root.\\n- help_add_child: Add a new child node based on the given information.\\n\\n        This function helps create a new subtask (child node) in the logical tree.\\n        The input `info` should contain all information gathered so far that is relevant\\n        to the logic of the task. The function will use this information to call an LLM\\n        and determine the appropriate child node to add.\\n\\n        Args:\\n            info (str): Relevant information accumulated so far to guide the creation\\n                        of a new child task.\\n- help_return_to_parent: Decide whether to return to the parent node or add a new child node\\n        based on the given information.\\n\\n        This function helps manage the logical tree by using the accumulated\\n        information in `info`. It will call an LLM to determine whether the\\n        current task (node) is already completed. If the task is complete,\\n        it calls `return_to_parent`. Otherwise, it calls `help_add_child` to\\n        add a new subtask (child node).\\n\\n        Args:\\n            info (str): Relevant information accumulated so far to guide\\n                        the decision of whether to return to parent or add\\n                        a new child task.\\n\\nMake sure to follow the tool’s description carefully when providing arguments.\\n\\nHistorical tool calls are stored in /workspace/tool_calls_path.json; if you want to review them, please use `func_view_with_llm`.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_00_FskxDKccS6SWAbzJERG3Mg', 'type': 'function', 'function': {'name': 'func_guide', 'arguments': '{\"guidance\": \"Will Return Guidance\"}'}, 'index': 0, 'name': 'func_guide'}]}, {'role': 'tool', 'name': 'func_guide', 'tool_call_id': 'call_00_FskxDKccS6SWAbzJERG3Mg', 'content': '- The **current node** you are working on is:\\n  - Name: test github code\\n  - Description: MAIN_DIR/package/ is a GitHub package I downloaded.\\nPlease run tests with both **real** and **sample** data and output the prediction results.\\nYou **must compare the prediction results calculated by yourself with the results in the corresponding PMC article by calling func_fetch_info_from_pmc_with_llm**.\\nThe result should be equal to the paper, but perhaps due to some reason, it may not be correct.\\nAny test code you write using tools should be placed under MAIN_DIR/,\\nMAIN_DIR=/workspace. You must provide all necessary parameters to the tools.\\nWhen installing dependencies, the main goal is to minimize local resource consumption \\n(e.g., by using precompiled wheels whenever possible).\\nPlease note that when data missed you can use func_think tool.\\nIf any instructions exist in tool calls, follow them instead of the guidelines here.\\n\\n**Tool Call Generation Rules:**\\n\\nYou must **output \"I see the guidance\"** at first for me to check whether you know below guidance.\\n\\n1. If you plan to generate \\'help_add_child\\', \\'help_return_to_parent\\' or \\'func_human\\', you must generate exactly 1 tool call.\\n\\n2. For any other tool calls, you must generate 3 different tool calls at one step.\\n   But these must not include \\'help_add_child\\', \\'help_return_to_parent\\' or \\'func_human\\'.\\n\\n3. When you find some data missing, you must always use func_human with enough information about the missing data.\\n\\n4. You need to set up maximum time, and consider the most easy and cost smallest method to deal with the problem.\\n\\n5. If you think the current task is completed, please use \\'help_return_to_parent\\' tool call.\\n\\n6. You must use at least one tool call.'}]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m tc \u001b[38;5;241m=\u001b[39m Tool_Calls(PATH\u001b[38;5;241m=\u001b[39mtool_calls_path, ENV_PATH\u001b[38;5;241m=\u001b[39menv_tool_calls_path, MAX_CHAR\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n\u001b[1;32m     32\u001b[0m tc\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 34\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgoal_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgoal_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgithub_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/lungproject/lungegfr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/yuanwen/Desktop/Docker_Environment/intern2/3/code/logical_tree1.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhether_recreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhuman_decision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Docker_Environment/intern2/3/code/src/utils/build_agent.py:413\u001b[0m, in \u001b[0;36mbuild_agent\u001b[0;34m(goal_list, ct, max_steps, tc, tree_filepath, github_url, package_name, verbose, whether_recreate, human_decision, base_commit, tools)\u001b[0m\n\u001b[1;32m    403\u001b[0m guidance \u001b[38;5;241m=\u001b[39m get_prompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_guidance_prompt.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    404\u001b[0m     current_node_name\u001b[38;5;241m=\u001b[39mtree\u001b[38;5;241m.\u001b[39mcurrent_node\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    405\u001b[0m     current_node_description\u001b[38;5;241m=\u001b[39mtree\u001b[38;5;241m.\u001b[39mcurrent_node\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m extra_guide_tool_call\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m    408\u001b[0m     get_func_tool_call(\n\u001b[1;32m    409\u001b[0m         func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc_guide\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m=\u001b[39mguidance, guidance\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWill Return Guidance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m )\n\u001b[0;32m--> 413\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_with_tools_by_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_prompt_for_build_agent_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgoal_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_filepath\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_guide_tool_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_guide_tool_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_condition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_condition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_start_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI see the guidance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[INFO] Finished processing goal \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Docker_Environment/intern2/3/code/src/services/llm.py:588\u001b[0m, in \u001b[0;36mLLM.query_with_tools_by_attention\u001b[0;34m(self, prompt, max_steps, tc, extra_guide_tool_call, tools, verbose, stop_condition, check_start_prompt)\u001b[0m\n\u001b[1;32m    586\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_text\u001b[38;5;241m.\u001b[39mstartswith(check_start_prompt):\n\u001b[0;32m--> 588\u001b[0m     out_text, tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_messages_with_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_guide_tool_call\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprevious_tool_calls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmax_chunk_id\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra_guide_tool_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_text\u001b[38;5;241m.\u001b[39mstartswith(check_start_prompt):\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[WARN] Check failed, regenerating...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Docker_Environment/intern2/3/code/src/services/llm.py:361\u001b[0m, in \u001b[0;36mLLM.query_messages_with_tools\u001b[0;34m(self, messages, tools, verbose)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse JSON from line: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from src.utils.prompts import get_prompt\n",
    "\n",
    "package_name = \"package\"\n",
    "\n",
    "goal_list = [\n",
    "    (\n",
    "        \"test github code\",\n",
    "        get_prompt(\"github_test_prompt.txt\").format(\n",
    "            package_name=package_name, MAIN_DIR=ct.MAIN_DIR\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"build agent\",\n",
    "        get_prompt(\"build_agent_prompt.txt\").format(\n",
    "            package_name=package_name,\n",
    "            MAIN_DIR=ct.MAIN_DIR,\n",
    "            MAIN_DATA_DIR=ct.MAIN_DATA_DIR,\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"improve agent\",\n",
    "        \"try to make the agent better by train a new model by yourself with the training data\"\n",
    "        \"and then test it on the test data, compare the result with the original result.\"\n",
    "        \"You must finally give me a better performance agent (compare to the original one)\"\n",
    "        \"You can try anything.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# goal_list = [(\"test\", \"please generate help_return_to_parent directly\")]\n",
    "\n",
    "tc = Tool_Calls(PATH=tool_calls_path, ENV_PATH=env_tool_calls_path, MAX_CHAR=100000)\n",
    "tc.clear()\n",
    "\n",
    "message = build_agent(\n",
    "    goal_list=goal_list,\n",
    "    ct=ct,\n",
    "    max_steps=10000,\n",
    "    tc=tc,\n",
    "    github_url=\"https://github.com/lungproject/lungegfr\",\n",
    "    tree_filepath=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/code/logical_tree1.json\",\n",
    "    package_name=package_name,\n",
    "    verbose=True,\n",
    "    whether_recreate=False,\n",
    "    human_decision=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_from_disk\n\u001b[1;32m      2\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_from_disk(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/yuanwen/Desktop/Docker_Environment/intern2/4/data/SWE-bench_Lite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(ds)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/datasets/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Column, Dataset\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/datasets/arrow_dataset.py:104\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesystems\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_remote_filesystem\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfingerprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     fingerprint_transform,\n\u001b[1;32m     94\u001b[0m     format_kwargs_for_fingerprint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     validate_fingerprint,\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_table, get_format_type_from_alias, get_formatter, query_table\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyDict, _is_range_contiguous\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo, DatasetInfosDict\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/datasets/formatting/__init__.py:91\u001b[0m\n\u001b[1;32m     88\u001b[0m     _register_unavailable_formatter(_polars_error, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m, aliases\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mTORCH_AVAILABLE:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_formatter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchFormatter\n\u001b[1;32m     93\u001b[0m     _register_formatter(TorchFormatter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, aliases\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Import torch once at module level once\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     _torch_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/__init__.py:2486\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 2486\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_meta_registrations.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _add_op_to_registry,\n\u001b[1;32m     12\u001b[0m     _convert_out_params,\n\u001b[1;32m     13\u001b[0m     global_decomposition_table,\n\u001b[1;32m     14\u001b[0m     meta_table,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_decomp/__init__.py:249\u001b[0m\n\u001b[1;32m    245\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_decomp/decompositions.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_meta_registrations\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_prims/__init__.py:523\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# Elementwise unary operations\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28mabs\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_make_elementwise_unary_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPLEX_TO_FLOAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m acos \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    532\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macos,\n\u001b[1;32m    533\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    534\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[1;32m    535\u001b[0m )\n\u001b[1;32m    537\u001b[0m acosh \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macosh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macosh,\n\u001b[1;32m    540\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    541\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[1;32m    542\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_prims/__init__.py:491\u001b[0m, in \u001b[0;36m_make_elementwise_unary_prim\u001b[0;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_elementwise_unary_prim\u001b[39m(\n\u001b[1;32m    485\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, type_promotion: ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    486\u001b[0m ):\n\u001b[1;32m    487\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    Creates an elementwise unary prim.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_make_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m(Tensor self) -> Tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prim_elementwise_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_promotion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRETURN_TYPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_prims/__init__.py:319\u001b[0m, in \u001b[0;36m_make_prim\u001b[0;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info\u001b[38;5;241m.\u001b[39mis_write:\n\u001b[1;32m    318\u001b[0m         mutates_args\u001b[38;5;241m.\u001b[39mappend(arg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 319\u001b[0m prim_def \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprims::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m prim_def\u001b[38;5;241m.\u001b[39mregister_fake(meta)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# all view ops get conj/neg fallthroughs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_library/custom_ops.py:157\u001b[0m, in \u001b[0;36mcustom_op\u001b[0;34m(name, fn, mutates_args, device_types, schema)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_library/custom_ops.py:138\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    135\u001b[0m     schema_str \u001b[38;5;241m=\u001b[39m schema\n\u001b[1;32m    137\u001b[0m namespace, opname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_library/custom_ops.py:186\u001b[0m, in \u001b[0;36mCustomOpDef.__init__\u001b[0;34m(self, namespace, name, schema, fn)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vmap_fn: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m get_library_allowing_overwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_to_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disabled_kernel: Set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    188\u001b[0m OPDEFS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qualname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_library/custom_ops.py:616\u001b[0m, in \u001b[0;36mCustomOpDef._register_to_dispatcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    609\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was no fake impl registered for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is necessary for torch.compile/export/fx tracing to work. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.register_fake` to add an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake impl.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m         )\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_abstract_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 616\u001b[0m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m autograd_impl \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mmake_autograd_impl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opoverload, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    619\u001b[0m lib\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, autograd_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m, with_keyset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/library.py:163\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_register_fake\u001b[39m(\u001b[38;5;28mself\u001b[39m, op_name, fn, _stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Registers the fake impl for an operator defined in the library.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(_stacklevel)\n\u001b[1;32m    165\u001b[0m     caller_module \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(frame)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/site-packages/torch/_library/utils.py:42\u001b[0m, in \u001b[0;36mget_source\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_source\u001b[39m(stacklevel: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a string that represents the caller.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Example: \"/path/to/foo.py:42\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    etc.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mlineno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m source\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/inspect.py:1505\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1503\u001b[0m start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1507\u001b[0m     lines \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/inspect.py:829\u001b[0m, in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource code not available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 829\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module:\n\u001b[1;32m    831\u001b[0m     lines \u001b[38;5;241m=\u001b[39m linecache\u001b[38;5;241m.\u001b[39mgetlines(file, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/inspect.py:755\u001b[0m, in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    752\u001b[0m         f \u001b[38;5;241m=\u001b[39m getabsfile(module)\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[1;32m    754\u001b[0m         modulesbyfile[f] \u001b[38;5;241m=\u001b[39m modulesbyfile[\n\u001b[0;32m--> 755\u001b[0m             \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m modulesbyfile:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(modulesbyfile[file])\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/posixpath.py:392\u001b[0m, in \u001b[0;36mrealpath\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the canonical path of the specified filename, eliminating any\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03msymbolic links encountered in the path.\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(filename)\n\u001b[0;32m--> 392\u001b[0m     path, ok \u001b[38;5;241m=\u001b[39m \u001b[43m_joinrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m abspath(path)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/posixpath.py:426\u001b[0m, in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, seen)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    425\u001b[0m newpath \u001b[38;5;241m=\u001b[39m join(path, name)\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mislink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    427\u001b[0m     path \u001b[38;5;241m=\u001b[39m newpath\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_early/lib/python3.9/posixpath.py:167\u001b[0m, in \u001b[0;36mislink\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a symbolic link\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"/Users/yuanwen/Desktop/Docker_Environment/intern2/4/data/SWE-bench_Lite\")\n",
    "print(ds)\n",
    "sample = ds[0]\n",
    "package_name = \"package\"\n",
    "\n",
    "tc = Tool_Calls(PATH=tool_calls_path, ENV_PATH=env_tool_calls_path, MAX_CHAR=100000)\n",
    "tc.clear()\n",
    "\n",
    "message = build_agent(\n",
    "    sample=sample,\n",
    "    ct=ct,\n",
    "    max_steps=10000,\n",
    "    tc=tc,\n",
    "    tree_filepath=\"/Users/yuanwen/Desktop/Docker_Environment/intern2/3/code/logical_tree_fix_issue.json\",\n",
    "    package_name=package_name,\n",
    "    verbose=True,\n",
    "    whether_recreate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prompt step 1 ===\n",
      "\n",
      "Failed to parse JSON from line: -alive\n",
      "根据之前的tool calls记录，我找到了一个已经没有用的tool call：\n",
      "\n",
      "**call_01_ON4j8QJUR3YBW6IeJZzG4GuB**\n",
      "\n",
      "这个tool call是用来修改文件路径的：\n",
      "- 函数名：func_modify\n",
      "- 文件路径：package/test_allpatient.py  \n",
      "- 修改内容：将`\"./Results/Hebeipredicttest.txt\"`改为`\"/workspace/package/Results/Hebeipredicttest.txt\"`\n",
      "\n",
      "这个修改已经执行过并且成功了，现在这个tool call已经没有用了，因为：\n",
      "1. 文件修改已经完成\n",
      "2. 后续的测试运行已经使用了新的路径\n",
      "3. 预测结果已经成功生成在指定位置"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'根据之前的tool calls记录，我找到了一个已经没有用的tool call：\\n\\n**call_01_ON4j8QJUR3YBW6IeJZzG4GuB**\\n\\n这个tool call是用来修改文件路径的：\\n- 函数名：func_modify\\n- 文件路径：package/test_allpatient.py  \\n- 修改内容：将`\"./Results/Hebeipredicttest.txt\"`改为`\"/workspace/package/Results/Hebeipredicttest.txt\"`\\n\\n这个修改已经执行过并且成功了，现在这个tool call已经没有用了，因为：\\n1. 文件修改已经完成\\n2. 后续的测试运行已经使用了新的路径\\n3. 预测结果已经成功生成在指定位置'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = \"\"\"\n",
    "你觉得这里有哪些以前调用过的tool calls已经没有用了, 我指的是以前调用过, 比如:\n",
    "{\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"\",\n",
    "    \"tool_calls\": [\n",
    "      {\n",
    "        \"id\": \"call_00_aBZLoDEh8lIVr9xgbfiS9COe\",\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"func_modify\",\n",
    "          \"arguments\": {\n",
    "            \"filepath\": \"package/test_allpatient.py\",\n",
    "            \"old_text\": \"np.savetxt(\\\"./Results/Hebeipredicttrain.txt\\\",predicttrainpetct1 )\",\n",
    "            \"new_text\": \"np.savetxt(\\\"/workspace/package/Results/Hebeipredicttrain.txt\\\",predicttrainpetct1 )\"\n",
    "          }\n",
    "        },\n",
    "        \"index\": 0,\n",
    "        \"name\": \"func_modify\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"call_01_ON4j8QJUR3YBW6IeJZzG4GuB\",\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"func_modify\",\n",
    "          \"arguments\": {\n",
    "            \"filepath\": \"package/test_allpatient.py\",\n",
    "            \"old_text\": \"np.savetxt(\\\"./Results/Hebeipredicttest.txt\\\",predicttestpetct1 )\",\n",
    "            \"new_text\": \"np.savetxt(\\\"/workspace/package/Results/Hebeipredicttest.txt\\\",predicttestpetct1 )\"\n",
    "          }\n",
    "        },\n",
    "        \"index\": 1,\n",
    "        \"name\": \"func_modify\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"call_02_BFycuTYRUdoCYBJPu9W6HVUC\",\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": \"func_modify\",\n",
    "          \"arguments\": {\n",
    "            \"filepath\": \"package/test_allpatient.py\",\n",
    "            \"old_text\": \"np.savetxt(\\\"./Results/Harbinpdlpredicttest.txt\\\",predicttestpetct1 )\",\n",
    "            \"new_text\": \"np.savetxt(\\\"/workspace/package/Results/Harbinpdlpredicttest.txt\\\",predicttestpetct1 )\"\n",
    "          }\n",
    "        },\n",
    "        \"index\": 2,\n",
    "        \"name\": \"func_modify\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": \"func_modify\",\n",
    "    \"tool_call_id\": \"call_00_aBZLoDEh8lIVr9xgbfiS9COe\",\n",
    "    \"content\": \"Written to package/test_allpatient.py\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": \"func_modify\",\n",
    "    \"tool_call_id\": \"call_01_ON4j8QJUR3YBW6IeJZzG4GuB\",\n",
    "    \"content\": \"Written to package/test_allpatient.py\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": \"func_modify\",\n",
    "    \"tool_call_id\": \"call_02_BFycuTYRUdoCYBJPu9W6HVUC\",\n",
    "    \"content\": \"Written to package/test_allpatient.py\"\n",
    "  },\n",
    "请你直接输出对应tool_call_id(上面的为call_01_ON4j8QJUR3YBW6IeJZzG4GuB)\n",
    "\"\"\"\n",
    "\n",
    "tc = Tool_Calls(PATH=tool_calls_path)\n",
    "query_based_on_tool_calls(\n",
    "    request=request,\n",
    "    ct=ct,\n",
    "    tc=tc,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LLM] Query\n",
      "  [SYSTEM PROMPT]\n",
      "    \n",
      "  [INPUT]\n",
      "    测试\n",
      "  [OUTPUT]\n",
      "    您好！我很乐意为您提供帮助！😊\n",
      "    \n",
      "    看起来您是在测试我的功能，这是完全正常的！让我简单介绍一下我能为您做些什么：\n",
      "    \n",
      "    **我能帮您：**\n",
      "    - 回答各种问题和解答疑惑\n",
      "    - 协助写作、翻译、编程等任务\n",
      "    - 分析和处理您上传的文件（图片、PDF、Word、Excel等）\n",
      "    - 进行创意思考和问题解决\n",
      "    - 提供学习和工作上的支持\n",
      "    \n",
      "    **我的特点：**\n",
      "    - 完全免费使用\n",
      "    - 支持128K上下文长度\n",
      "    - 可以联网搜索（需要您手动开启）\n",
      "    - 知识更新到2024年7月\n",
      "    \n",
      "    请随时告诉我您需要什么帮助，或者想测试什么具体功能。我会尽我所能为您提供最好的服务！✨\n",
      "    \n",
      "    有什么具体的问题或任务想要尝试吗？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您好！我很乐意为您提供帮助！😊\\n\\n看起来您是在测试我的功能，这是完全正常的！让我简单介绍一下我能为您做些什么：\\n\\n**我能帮您：**\\n- 回答各种问题和解答疑惑\\n- 协助写作、翻译、编程等任务\\n- 分析和处理您上传的文件（图片、PDF、Word、Excel等）\\n- 进行创意思考和问题解决\\n- 提供学习和工作上的支持\\n\\n**我的特点：**\\n- 完全免费使用\\n- 支持128K上下文长度\\n- 可以联网搜索（需要您手动开启）\\n- 知识更新到2024年7月\\n\\n请随时告诉我您需要什么帮助，或者想测试什么具体功能。我会尽我所能为您提供最好的服务！✨\\n\\n有什么具体的问题或任务想要尝试吗？'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.llm.system_prompt = \"\"\n",
    "ct.llm.query(\"测试\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_early",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
